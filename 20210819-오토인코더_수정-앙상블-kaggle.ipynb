{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c102ae40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "## 라이브러리 불러오기\n",
    "'''메인 라이브러리'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "import pickle, gzip\n",
    "\n",
    "'''시각화 관련 라이브러리'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "'''데이터 준비 및 모델 평가 관련 라이브러리'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "'''알고리즘 관련 라이브러리'''\n",
    "import lightgbm as lgb\n",
    "\n",
    "'''텐서플로 및 케라스 관련 라이브러리'''\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers import BatchNormalization, Input, Lambda\n",
    "from keras import regularizers\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def encode_features(dataDF):\n",
    "    features = ['userip','phone','identikey','CPID','dnGrade','age','cs','isNew','amtlimit']\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(dataDF[feature])\n",
    "        dataDF[feature] = le.transform(dataDF[feature])\n",
    "        # decode\n",
    "        # le.inverse_transform(dataDF[feature])\n",
    "        \n",
    "    return dataDF\n",
    "\n",
    "df = pd.read_csv('C://Users/USER/20210906/credit_card/creditcard.csv')\n",
    "\n",
    "#df = df.drop([\"miAMT2th\",\"miAMT3th\",\"isCTR\",\"dnpoint\",\"lastUsedCP\"],axis=1)\n",
    "\n",
    "#df = encode_features(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0912cae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4a78c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  0.105915  0.253844  0.081080    3.67      0  \n",
       "6 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  0.094199  0.246219  0.083076    3.68      0  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc2c7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(df.drop('isSuspect', axis=1), df['isSuspect'], \n",
    "#                                                     test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba29364",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test,y_train, y_test= train_test_split(X, y,train_size=0.7, \n",
    "                                                    test_size=0.3, random_state=121)\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=0)\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "# start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8aba3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "\n",
    "# 수정된 get_clf_eval() 함수 \n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    #print('오차 행렬')\n",
    "    #print(confusion)\n",
    "    \n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36968ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  70 out of  70 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간: 14.3 초 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=12)]: Done  70 out of  70 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9995, 정밀도: 0.9453, 재현율: 0.7806,    F1: 0.8551, AUC:0.9450\n",
      "[[85281     7]\n",
      " [   34   121]]\n",
      "8.19652935528442e-05 0.0003985231202016058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(n_estimators=70, max_depth=18, min_samples_leaf=3, \\\n",
    "                                 min_samples_split=2, criterion='entropy', random_state=0, verbose=1,  n_jobs=-1, warm_start=True)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "#%time print(rf_clf.fit(X_train , y_train))\n",
    "print(\"수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n",
    "pred = rf_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "pred_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# true/false positives/negatives\n",
    "(tp, fp, \n",
    " fn, tn) = cm.flatten()\n",
    "\n",
    "FPR = fp / (tp+tn) \n",
    "FNR = fn / (tp+fn) \n",
    "\n",
    "print(FPR, FNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa14e5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.59835\n",
      "[1]\tvalidation_0-logloss:0.52081\n",
      "[2]\tvalidation_0-logloss:0.45606\n",
      "[3]\tvalidation_0-logloss:0.40134\n",
      "[4]\tvalidation_0-logloss:0.35464\n",
      "[5]\tvalidation_0-logloss:0.31441\n",
      "[6]\tvalidation_0-logloss:0.27949\n",
      "[7]\tvalidation_0-logloss:0.24906\n",
      "[8]\tvalidation_0-logloss:0.22240\n",
      "[9]\tvalidation_0-logloss:0.19889\n",
      "[10]\tvalidation_0-logloss:0.17818\n",
      "[11]\tvalidation_0-logloss:0.15982\n",
      "[12]\tvalidation_0-logloss:0.14353\n",
      "[13]\tvalidation_0-logloss:0.12904\n",
      "[14]\tvalidation_0-logloss:0.11614\n",
      "[15]\tvalidation_0-logloss:0.10463\n",
      "[16]\tvalidation_0-logloss:0.09433\n",
      "[17]\tvalidation_0-logloss:0.08512\n",
      "[18]\tvalidation_0-logloss:0.07687\n",
      "[19]\tvalidation_0-logloss:0.06946\n",
      "[20]\tvalidation_0-logloss:0.06282\n",
      "[21]\tvalidation_0-logloss:0.05685\n",
      "[22]\tvalidation_0-logloss:0.05150\n",
      "[23]\tvalidation_0-logloss:0.04668\n",
      "[24]\tvalidation_0-logloss:0.04234\n",
      "[25]\tvalidation_0-logloss:0.03844\n",
      "[26]\tvalidation_0-logloss:0.03492\n",
      "[27]\tvalidation_0-logloss:0.03175\n",
      "[28]\tvalidation_0-logloss:0.02890\n",
      "[29]\tvalidation_0-logloss:0.02633\n",
      "[30]\tvalidation_0-logloss:0.02401\n",
      "[31]\tvalidation_0-logloss:0.02193\n",
      "[32]\tvalidation_0-logloss:0.02004\n",
      "[33]\tvalidation_0-logloss:0.01834\n",
      "[34]\tvalidation_0-logloss:0.01680\n",
      "[35]\tvalidation_0-logloss:0.01542\n",
      "[36]\tvalidation_0-logloss:0.01417\n",
      "[37]\tvalidation_0-logloss:0.01305\n",
      "[38]\tvalidation_0-logloss:0.01203\n",
      "[39]\tvalidation_0-logloss:0.01112\n",
      "[40]\tvalidation_0-logloss:0.01029\n",
      "[41]\tvalidation_0-logloss:0.00955\n",
      "[42]\tvalidation_0-logloss:0.00888\n",
      "[43]\tvalidation_0-logloss:0.00828\n",
      "[44]\tvalidation_0-logloss:0.00773\n",
      "[45]\tvalidation_0-logloss:0.00724\n",
      "[46]\tvalidation_0-logloss:0.00679\n",
      "[47]\tvalidation_0-logloss:0.00639\n",
      "[48]\tvalidation_0-logloss:0.00604\n",
      "[49]\tvalidation_0-logloss:0.00572\n",
      "[50]\tvalidation_0-logloss:0.00543\n",
      "[51]\tvalidation_0-logloss:0.00517\n",
      "[52]\tvalidation_0-logloss:0.00493\n",
      "[53]\tvalidation_0-logloss:0.00472\n",
      "[54]\tvalidation_0-logloss:0.00453\n",
      "[55]\tvalidation_0-logloss:0.00435\n",
      "[56]\tvalidation_0-logloss:0.00420\n",
      "[57]\tvalidation_0-logloss:0.00406\n",
      "[58]\tvalidation_0-logloss:0.00393\n",
      "[59]\tvalidation_0-logloss:0.00382\n",
      "[60]\tvalidation_0-logloss:0.00372\n",
      "[61]\tvalidation_0-logloss:0.00363\n",
      "[62]\tvalidation_0-logloss:0.00355\n",
      "[63]\tvalidation_0-logloss:0.00349\n",
      "[64]\tvalidation_0-logloss:0.00343\n",
      "[65]\tvalidation_0-logloss:0.00337\n",
      "[66]\tvalidation_0-logloss:0.00332\n",
      "[67]\tvalidation_0-logloss:0.00327\n",
      "[68]\tvalidation_0-logloss:0.00323\n",
      "[69]\tvalidation_0-logloss:0.00319\n",
      "[70]\tvalidation_0-logloss:0.00316\n",
      "[71]\tvalidation_0-logloss:0.00313\n",
      "[72]\tvalidation_0-logloss:0.00311\n",
      "[73]\tvalidation_0-logloss:0.00308\n",
      "[74]\tvalidation_0-logloss:0.00305\n",
      "[75]\tvalidation_0-logloss:0.00303\n",
      "[76]\tvalidation_0-logloss:0.00301\n",
      "[77]\tvalidation_0-logloss:0.00300\n",
      "[78]\tvalidation_0-logloss:0.00298\n",
      "[79]\tvalidation_0-logloss:0.00296\n",
      "[80]\tvalidation_0-logloss:0.00295\n",
      "[81]\tvalidation_0-logloss:0.00293\n",
      "[82]\tvalidation_0-logloss:0.00293\n",
      "[83]\tvalidation_0-logloss:0.00292\n",
      "[84]\tvalidation_0-logloss:0.00291\n",
      "[85]\tvalidation_0-logloss:0.00290\n",
      "[86]\tvalidation_0-logloss:0.00289\n",
      "[87]\tvalidation_0-logloss:0.00289\n",
      "[88]\tvalidation_0-logloss:0.00288\n",
      "[89]\tvalidation_0-logloss:0.00288\n",
      "[90]\tvalidation_0-logloss:0.00287\n",
      "[91]\tvalidation_0-logloss:0.00286\n",
      "[92]\tvalidation_0-logloss:0.00286\n",
      "[93]\tvalidation_0-logloss:0.00285\n",
      "[94]\tvalidation_0-logloss:0.00284\n",
      "[95]\tvalidation_0-logloss:0.00283\n",
      "[96]\tvalidation_0-logloss:0.00282\n",
      "[97]\tvalidation_0-logloss:0.00282\n",
      "[98]\tvalidation_0-logloss:0.00282\n",
      "[99]\tvalidation_0-logloss:0.00280\n",
      "[100]\tvalidation_0-logloss:0.00280\n",
      "[101]\tvalidation_0-logloss:0.00280\n",
      "[102]\tvalidation_0-logloss:0.00279\n",
      "[103]\tvalidation_0-logloss:0.00278\n",
      "[104]\tvalidation_0-logloss:0.00278\n",
      "[105]\tvalidation_0-logloss:0.00276\n",
      "[106]\tvalidation_0-logloss:0.00276\n",
      "[107]\tvalidation_0-logloss:0.00276\n",
      "[108]\tvalidation_0-logloss:0.00276\n",
      "[109]\tvalidation_0-logloss:0.00275\n",
      "[110]\tvalidation_0-logloss:0.00275\n",
      "[111]\tvalidation_0-logloss:0.00275\n",
      "[112]\tvalidation_0-logloss:0.00275\n",
      "[113]\tvalidation_0-logloss:0.00275\n",
      "[114]\tvalidation_0-logloss:0.00275\n",
      "[115]\tvalidation_0-logloss:0.00274\n",
      "[116]\tvalidation_0-logloss:0.00274\n",
      "[117]\tvalidation_0-logloss:0.00273\n",
      "[118]\tvalidation_0-logloss:0.00273\n",
      "[119]\tvalidation_0-logloss:0.00273\n",
      "[120]\tvalidation_0-logloss:0.00272\n",
      "[121]\tvalidation_0-logloss:0.00272\n",
      "[122]\tvalidation_0-logloss:0.00271\n",
      "[123]\tvalidation_0-logloss:0.00271\n",
      "[124]\tvalidation_0-logloss:0.00271\n",
      "[125]\tvalidation_0-logloss:0.00271\n",
      "[126]\tvalidation_0-logloss:0.00270\n",
      "[127]\tvalidation_0-logloss:0.00270\n",
      "[128]\tvalidation_0-logloss:0.00269\n",
      "[129]\tvalidation_0-logloss:0.00268\n",
      "[130]\tvalidation_0-logloss:0.00268\n",
      "[131]\tvalidation_0-logloss:0.00267\n",
      "[132]\tvalidation_0-logloss:0.00267\n",
      "[133]\tvalidation_0-logloss:0.00267\n",
      "[134]\tvalidation_0-logloss:0.00267\n",
      "[135]\tvalidation_0-logloss:0.00266\n",
      "[136]\tvalidation_0-logloss:0.00266\n",
      "[137]\tvalidation_0-logloss:0.00266\n",
      "[138]\tvalidation_0-logloss:0.00265\n",
      "[139]\tvalidation_0-logloss:0.00264\n",
      "[140]\tvalidation_0-logloss:0.00264\n",
      "[141]\tvalidation_0-logloss:0.00264\n",
      "[142]\tvalidation_0-logloss:0.00263\n",
      "[143]\tvalidation_0-logloss:0.00263\n",
      "[144]\tvalidation_0-logloss:0.00262\n",
      "[145]\tvalidation_0-logloss:0.00262\n",
      "[146]\tvalidation_0-logloss:0.00262\n",
      "[147]\tvalidation_0-logloss:0.00262\n",
      "[148]\tvalidation_0-logloss:0.00262\n",
      "[149]\tvalidation_0-logloss:0.00261\n",
      "[150]\tvalidation_0-logloss:0.00261\n",
      "[151]\tvalidation_0-logloss:0.00261\n",
      "[152]\tvalidation_0-logloss:0.00261\n",
      "[153]\tvalidation_0-logloss:0.00260\n",
      "[154]\tvalidation_0-logloss:0.00260\n",
      "[155]\tvalidation_0-logloss:0.00260\n",
      "[156]\tvalidation_0-logloss:0.00260\n",
      "[157]\tvalidation_0-logloss:0.00260\n",
      "[158]\tvalidation_0-logloss:0.00260\n",
      "[159]\tvalidation_0-logloss:0.00260\n",
      "[160]\tvalidation_0-logloss:0.00260\n",
      "[161]\tvalidation_0-logloss:0.00260\n",
      "[162]\tvalidation_0-logloss:0.00260\n",
      "[163]\tvalidation_0-logloss:0.00259\n",
      "[164]\tvalidation_0-logloss:0.00259\n",
      "[165]\tvalidation_0-logloss:0.00259\n",
      "[166]\tvalidation_0-logloss:0.00260\n",
      "[167]\tvalidation_0-logloss:0.00259\n",
      "[168]\tvalidation_0-logloss:0.00259\n",
      "[169]\tvalidation_0-logloss:0.00260\n",
      "[170]\tvalidation_0-logloss:0.00260\n",
      "[171]\tvalidation_0-logloss:0.00259\n",
      "[172]\tvalidation_0-logloss:0.00259\n",
      "[173]\tvalidation_0-logloss:0.00260\n",
      "[174]\tvalidation_0-logloss:0.00260\n",
      "[175]\tvalidation_0-logloss:0.00259\n",
      "[176]\tvalidation_0-logloss:0.00260\n",
      "[177]\tvalidation_0-logloss:0.00259\n",
      "[178]\tvalidation_0-logloss:0.00259\n",
      "[179]\tvalidation_0-logloss:0.00259\n",
      "[180]\tvalidation_0-logloss:0.00258\n",
      "[181]\tvalidation_0-logloss:0.00258\n",
      "[182]\tvalidation_0-logloss:0.00258\n",
      "[183]\tvalidation_0-logloss:0.00258\n",
      "[184]\tvalidation_0-logloss:0.00258\n",
      "[185]\tvalidation_0-logloss:0.00258\n",
      "[186]\tvalidation_0-logloss:0.00258\n",
      "[187]\tvalidation_0-logloss:0.00258\n",
      "[188]\tvalidation_0-logloss:0.00258\n",
      "[189]\tvalidation_0-logloss:0.00258\n",
      "[190]\tvalidation_0-logloss:0.00258\n",
      "[191]\tvalidation_0-logloss:0.00258\n",
      "[192]\tvalidation_0-logloss:0.00257\n",
      "[193]\tvalidation_0-logloss:0.00257\n",
      "[194]\tvalidation_0-logloss:0.00258\n",
      "[195]\tvalidation_0-logloss:0.00257\n",
      "[196]\tvalidation_0-logloss:0.00257\n",
      "[197]\tvalidation_0-logloss:0.00257\n",
      "[198]\tvalidation_0-logloss:0.00257\n",
      "[199]\tvalidation_0-logloss:0.00256\n",
      "[200]\tvalidation_0-logloss:0.00256\n",
      "[201]\tvalidation_0-logloss:0.00256\n",
      "[202]\tvalidation_0-logloss:0.00256\n",
      "[203]\tvalidation_0-logloss:0.00256\n",
      "[204]\tvalidation_0-logloss:0.00255\n",
      "[205]\tvalidation_0-logloss:0.00255\n",
      "[206]\tvalidation_0-logloss:0.00255\n",
      "[207]\tvalidation_0-logloss:0.00255\n",
      "[208]\tvalidation_0-logloss:0.00255\n",
      "[209]\tvalidation_0-logloss:0.00255\n",
      "[210]\tvalidation_0-logloss:0.00255\n",
      "[211]\tvalidation_0-logloss:0.00255\n",
      "[212]\tvalidation_0-logloss:0.00255\n",
      "[213]\tvalidation_0-logloss:0.00254\n",
      "[214]\tvalidation_0-logloss:0.00254\n",
      "[215]\tvalidation_0-logloss:0.00254\n",
      "[216]\tvalidation_0-logloss:0.00254\n",
      "[217]\tvalidation_0-logloss:0.00254\n",
      "[218]\tvalidation_0-logloss:0.00254\n",
      "[219]\tvalidation_0-logloss:0.00254\n",
      "[220]\tvalidation_0-logloss:0.00254\n",
      "[221]\tvalidation_0-logloss:0.00254\n",
      "[222]\tvalidation_0-logloss:0.00254\n",
      "[223]\tvalidation_0-logloss:0.00254\n",
      "[224]\tvalidation_0-logloss:0.00254\n",
      "[225]\tvalidation_0-logloss:0.00254\n",
      "[226]\tvalidation_0-logloss:0.00254\n",
      "[227]\tvalidation_0-logloss:0.00254\n",
      "[228]\tvalidation_0-logloss:0.00254\n",
      "[229]\tvalidation_0-logloss:0.00254\n",
      "[230]\tvalidation_0-logloss:0.00254\n",
      "[231]\tvalidation_0-logloss:0.00254\n",
      "[232]\tvalidation_0-logloss:0.00254\n",
      "[233]\tvalidation_0-logloss:0.00255\n",
      "[234]\tvalidation_0-logloss:0.00255\n",
      "[235]\tvalidation_0-logloss:0.00254\n",
      "[236]\tvalidation_0-logloss:0.00254\n",
      "[237]\tvalidation_0-logloss:0.00255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238]\tvalidation_0-logloss:0.00255\n",
      "[239]\tvalidation_0-logloss:0.00255\n",
      "[240]\tvalidation_0-logloss:0.00255\n",
      "[241]\tvalidation_0-logloss:0.00254\n",
      "[242]\tvalidation_0-logloss:0.00255\n",
      "[243]\tvalidation_0-logloss:0.00255\n",
      "[244]\tvalidation_0-logloss:0.00255\n",
      "[245]\tvalidation_0-logloss:0.00255\n",
      "[246]\tvalidation_0-logloss:0.00255\n",
      "[247]\tvalidation_0-logloss:0.00255\n",
      "[248]\tvalidation_0-logloss:0.00254\n",
      "[249]\tvalidation_0-logloss:0.00254\n",
      "[250]\tvalidation_0-logloss:0.00254\n",
      "[251]\tvalidation_0-logloss:0.00254\n",
      "[252]\tvalidation_0-logloss:0.00254\n",
      "[253]\tvalidation_0-logloss:0.00254\n",
      "[254]\tvalidation_0-logloss:0.00254\n",
      "[255]\tvalidation_0-logloss:0.00254\n",
      "[256]\tvalidation_0-logloss:0.00254\n",
      "[257]\tvalidation_0-logloss:0.00254\n",
      "[258]\tvalidation_0-logloss:0.00254\n",
      "[259]\tvalidation_0-logloss:0.00254\n",
      "[260]\tvalidation_0-logloss:0.00254\n",
      "[261]\tvalidation_0-logloss:0.00254\n",
      "[262]\tvalidation_0-logloss:0.00254\n",
      "[263]\tvalidation_0-logloss:0.00254\n",
      "[264]\tvalidation_0-logloss:0.00254\n",
      "[265]\tvalidation_0-logloss:0.00254\n",
      "[266]\tvalidation_0-logloss:0.00254\n",
      "[267]\tvalidation_0-logloss:0.00254\n",
      "[268]\tvalidation_0-logloss:0.00254\n",
      "[269]\tvalidation_0-logloss:0.00254\n",
      "[270]\tvalidation_0-logloss:0.00255\n",
      "[271]\tvalidation_0-logloss:0.00254\n",
      "[272]\tvalidation_0-logloss:0.00254\n",
      "[273]\tvalidation_0-logloss:0.00254\n",
      "[274]\tvalidation_0-logloss:0.00254\n",
      "[275]\tvalidation_0-logloss:0.00255\n",
      "[276]\tvalidation_0-logloss:0.00255\n",
      "[277]\tvalidation_0-logloss:0.00255\n",
      "[278]\tvalidation_0-logloss:0.00255\n",
      "[279]\tvalidation_0-logloss:0.00255\n",
      "[280]\tvalidation_0-logloss:0.00255\n",
      "[281]\tvalidation_0-logloss:0.00255\n",
      "[282]\tvalidation_0-logloss:0.00255\n",
      "[283]\tvalidation_0-logloss:0.00255\n",
      "[284]\tvalidation_0-logloss:0.00256\n",
      "[285]\tvalidation_0-logloss:0.00256\n",
      "[286]\tvalidation_0-logloss:0.00256\n",
      "[287]\tvalidation_0-logloss:0.00257\n",
      "[288]\tvalidation_0-logloss:0.00257\n",
      "[289]\tvalidation_0-logloss:0.00257\n",
      "[290]\tvalidation_0-logloss:0.00257\n",
      "[291]\tvalidation_0-logloss:0.00257\n",
      "[292]\tvalidation_0-logloss:0.00257\n",
      "[293]\tvalidation_0-logloss:0.00257\n",
      "[294]\tvalidation_0-logloss:0.00257\n",
      "[295]\tvalidation_0-logloss:0.00257\n",
      "[296]\tvalidation_0-logloss:0.00257\n",
      "[297]\tvalidation_0-logloss:0.00257\n",
      "[298]\tvalidation_0-logloss:0.00256\n",
      "[299]\tvalidation_0-logloss:0.00257\n",
      "[300]\tvalidation_0-logloss:0.00257\n",
      "[301]\tvalidation_0-logloss:0.00258\n",
      "[302]\tvalidation_0-logloss:0.00257\n",
      "[303]\tvalidation_0-logloss:0.00258\n",
      "[304]\tvalidation_0-logloss:0.00258\n",
      "[305]\tvalidation_0-logloss:0.00257\n",
      "[306]\tvalidation_0-logloss:0.00257\n",
      "[307]\tvalidation_0-logloss:0.00257\n",
      "[308]\tvalidation_0-logloss:0.00257\n",
      "[309]\tvalidation_0-logloss:0.00257\n",
      "[310]\tvalidation_0-logloss:0.00257\n",
      "[311]\tvalidation_0-logloss:0.00257\n",
      "[312]\tvalidation_0-logloss:0.00257\n",
      "[313]\tvalidation_0-logloss:0.00258\n",
      "[314]\tvalidation_0-logloss:0.00258\n",
      "[315]\tvalidation_0-logloss:0.00258\n",
      "[316]\tvalidation_0-logloss:0.00258\n",
      "[317]\tvalidation_0-logloss:0.00258\n",
      "[318]\tvalidation_0-logloss:0.00258\n",
      "수행 시간: 48.7 초 \n",
      "정확도: 0.9996, 정밀도: 0.9538, 재현율: 0.8000,    F1: 0.8702, AUC:0.9771\n",
      "[[85282     6]\n",
      " [   31   124]]\n",
      "0.046153846153846156 0.00036336783374163375\n"
     ]
    }
   ],
   "source": [
    "# 사이킷런 래퍼 XGBoost 클래스인 XGBClassifier 임포트\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "evals = [(X_test, y_test)]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_wrapper = XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "xgb_wrapper.fit(X_train , y_train,  early_stopping_rounds=100,eval_set=evals, eval_metric=\"logloss\",  verbose=True)\n",
    "print(\"수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n",
    "w_preds = xgb_wrapper.predict(X_test)\n",
    "w_pred_proba = xgb_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test ,w_preds, w_pred_proba)\n",
    "\n",
    "cm = confusion_matrix(y_test, w_preds)\n",
    "print(cm)\n",
    "# true/false positives/negatives\n",
    "(tp, fp, \n",
    " fn, tn) = cm.flatten()\n",
    "\n",
    "오탐률 = fp / (fp+tn)\n",
    "미탐률 = fn / (tp+fn) \n",
    "\n",
    "print(오탐률, 미탐률)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b475975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수행 시간: 267.9 초 \n",
      "정확도: 0.9990, 정밀도: 0.8586, 재현율: 0.5484,    F1: 0.6693, AUC:0.7224\n",
      "[[85274    14]\n",
      " [   70    85]]\n",
      "0.1414141414141414 0.0008202099737532808\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# GBM 수행 시간 측정을 위함. 시작 시간 설정.\n",
    "start_time = time.time()\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "gb_clf.fit(X_train , y_train)\n",
    "print(\"수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n",
    "gb_pred = gb_clf.predict(X_test)\n",
    "pred_proba = gb_clf.predict_proba(X_test)[:, 1]\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "\n",
    "get_clf_eval(y_test ,gb_pred, pred_proba)\n",
    "\n",
    "cm = confusion_matrix(y_test, gb_pred)\n",
    "print(cm)\n",
    "# true/false positives/negatives\n",
    "(tp, fp, \n",
    " fn, tn) = cm.flatten()\n",
    "\n",
    "오탐률 = fp / (fp+tn)\n",
    "미탐률 = fn / (tp+fn) \n",
    "\n",
    "print(오탐률, 미탐률)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be113d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c74b3cf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.00467122\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's binary_logloss: 0.00467947\n",
      "[3]\tvalid_0's binary_logloss: 0.0046474\n",
      "[4]\tvalid_0's binary_logloss: 0.00459939\n",
      "[5]\tvalid_0's binary_logloss: 0.00455491\n",
      "[6]\tvalid_0's binary_logloss: 0.00451539\n",
      "[7]\tvalid_0's binary_logloss: 0.00447591\n",
      "[8]\tvalid_0's binary_logloss: 0.00443311\n",
      "[9]\tvalid_0's binary_logloss: 0.00439069\n",
      "[10]\tvalid_0's binary_logloss: 0.00434473\n",
      "[11]\tvalid_0's binary_logloss: 0.00430785\n",
      "[12]\tvalid_0's binary_logloss: 0.00426609\n",
      "[13]\tvalid_0's binary_logloss: 0.00422657\n",
      "[14]\tvalid_0's binary_logloss: 0.00418834\n",
      "[15]\tvalid_0's binary_logloss: 0.00415286\n",
      "[16]\tvalid_0's binary_logloss: 0.00411821\n",
      "[17]\tvalid_0's binary_logloss: 0.00408479\n",
      "[18]\tvalid_0's binary_logloss: 0.00405359\n",
      "[19]\tvalid_0's binary_logloss: 0.00402302\n",
      "[20]\tvalid_0's binary_logloss: 0.00399187\n",
      "[21]\tvalid_0's binary_logloss: 0.00396229\n",
      "[22]\tvalid_0's binary_logloss: 0.00393529\n",
      "[23]\tvalid_0's binary_logloss: 0.00390942\n",
      "[24]\tvalid_0's binary_logloss: 0.00388367\n",
      "[25]\tvalid_0's binary_logloss: 0.0038605\n",
      "[26]\tvalid_0's binary_logloss: 0.00383598\n",
      "[27]\tvalid_0's binary_logloss: 0.00381387\n",
      "[28]\tvalid_0's binary_logloss: 0.00379145\n",
      "[29]\tvalid_0's binary_logloss: 0.00376988\n",
      "[30]\tvalid_0's binary_logloss: 0.00374742\n",
      "[31]\tvalid_0's binary_logloss: 0.00372807\n",
      "[32]\tvalid_0's binary_logloss: 0.00370974\n",
      "[33]\tvalid_0's binary_logloss: 0.00369057\n",
      "[34]\tvalid_0's binary_logloss: 0.00367368\n",
      "[35]\tvalid_0's binary_logloss: 0.00365697\n",
      "[36]\tvalid_0's binary_logloss: 0.00364224\n",
      "[37]\tvalid_0's binary_logloss: 0.00362734\n",
      "[38]\tvalid_0's binary_logloss: 0.00361456\n",
      "[39]\tvalid_0's binary_logloss: 0.00360074\n",
      "[40]\tvalid_0's binary_logloss: 0.00358922\n",
      "[41]\tvalid_0's binary_logloss: 0.00357938\n",
      "[42]\tvalid_0's binary_logloss: 0.00356656\n",
      "[43]\tvalid_0's binary_logloss: 0.00355809\n",
      "[44]\tvalid_0's binary_logloss: 0.00355021\n",
      "[45]\tvalid_0's binary_logloss: 0.00353818\n",
      "[46]\tvalid_0's binary_logloss: 0.00353149\n",
      "[47]\tvalid_0's binary_logloss: 0.00352145\n",
      "[48]\tvalid_0's binary_logloss: 0.00351364\n",
      "[49]\tvalid_0's binary_logloss: 0.00350628\n",
      "[50]\tvalid_0's binary_logloss: 0.0034981\n",
      "[51]\tvalid_0's binary_logloss: 0.00349043\n",
      "[52]\tvalid_0's binary_logloss: 0.00348387\n",
      "[53]\tvalid_0's binary_logloss: 0.00347913\n",
      "[54]\tvalid_0's binary_logloss: 0.00347154\n",
      "[55]\tvalid_0's binary_logloss: 0.0034639\n",
      "[56]\tvalid_0's binary_logloss: 0.00345668\n",
      "[57]\tvalid_0's binary_logloss: 0.00345147\n",
      "[58]\tvalid_0's binary_logloss: 0.00344376\n",
      "[59]\tvalid_0's binary_logloss: 0.00343804\n",
      "[60]\tvalid_0's binary_logloss: 0.00343241\n",
      "[61]\tvalid_0's binary_logloss: 0.00342829\n",
      "[62]\tvalid_0's binary_logloss: 0.00342305\n",
      "[63]\tvalid_0's binary_logloss: 0.0034222\n",
      "[64]\tvalid_0's binary_logloss: 0.00342056\n",
      "[65]\tvalid_0's binary_logloss: 0.00341837\n",
      "[66]\tvalid_0's binary_logloss: 0.00341466\n",
      "[67]\tvalid_0's binary_logloss: 0.003413\n",
      "[68]\tvalid_0's binary_logloss: 0.00341165\n",
      "[69]\tvalid_0's binary_logloss: 0.00341136\n",
      "[70]\tvalid_0's binary_logloss: 0.00341056\n",
      "[71]\tvalid_0's binary_logloss: 0.00341093\n",
      "[72]\tvalid_0's binary_logloss: 0.00341046\n",
      "[73]\tvalid_0's binary_logloss: 0.0034101\n",
      "[74]\tvalid_0's binary_logloss: 0.00341122\n",
      "[75]\tvalid_0's binary_logloss: 0.00341122\n",
      "[76]\tvalid_0's binary_logloss: 0.00341218\n",
      "[77]\tvalid_0's binary_logloss: 0.00341268\n",
      "[78]\tvalid_0's binary_logloss: 0.00341414\n",
      "[79]\tvalid_0's binary_logloss: 0.00341587\n",
      "[80]\tvalid_0's binary_logloss: 0.00341859\n",
      "[81]\tvalid_0's binary_logloss: 0.00342134\n",
      "[82]\tvalid_0's binary_logloss: 0.00342436\n",
      "[83]\tvalid_0's binary_logloss: 0.00342633\n",
      "[84]\tvalid_0's binary_logloss: 0.00342983\n",
      "[85]\tvalid_0's binary_logloss: 0.00343379\n",
      "[86]\tvalid_0's binary_logloss: 0.00343791\n",
      "[87]\tvalid_0's binary_logloss: 0.00344057\n",
      "[88]\tvalid_0's binary_logloss: 0.00344405\n",
      "[89]\tvalid_0's binary_logloss: 0.00344901\n",
      "[90]\tvalid_0's binary_logloss: 0.00345287\n",
      "[91]\tvalid_0's binary_logloss: 0.00345773\n",
      "[92]\tvalid_0's binary_logloss: 0.00346175\n",
      "[93]\tvalid_0's binary_logloss: 0.00346579\n",
      "[94]\tvalid_0's binary_logloss: 0.00347085\n",
      "[95]\tvalid_0's binary_logloss: 0.00347599\n",
      "[96]\tvalid_0's binary_logloss: 0.00348101\n",
      "[97]\tvalid_0's binary_logloss: 0.00348542\n",
      "[98]\tvalid_0's binary_logloss: 0.00348805\n",
      "[99]\tvalid_0's binary_logloss: 0.00349133\n",
      "[100]\tvalid_0's binary_logloss: 0.0034947\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[73]\tvalid_0's binary_logloss: 0.0034101\n",
      "수행 시간: 80.2 초 \n",
      "정확도: 0.9995, 정밀도: 0.9051, 재현율: 0.8000,    F1: 0.8493, AUC:0.9486\n",
      "[[85275    13]\n",
      " [   31   124]]\n",
      "0.0948905109489051 0.00036339765081002507\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "params = {\n",
    "    'application': 'binary', \n",
    "    'boosting': 'gbdt',\n",
    "    'num_iterations': 8, \n",
    "    'device': 'gpu', \n",
    "    'max_bin': 250, \n",
    "    'metric' : 'binary_logloss',\n",
    "    'n_estimators': 100, \n",
    "    'learning_rate': 0.03, \n",
    "    'num_leaves': 960, \n",
    "    'max_depth': -1, \n",
    "    'min_data_in_leaf': 4900, \n",
    "    'lambda_l1': 10, \n",
    "    'lambda_l2': 45, \n",
    "    'min_gain_to_split': 5.252490881397367, \n",
    "    'bagging_fraction': 0.5, \n",
    "    'bagging_freq': 1, \n",
    "    'feature_fraction': 0.7\n",
    "}\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 앞서 XGBoost와 동일하게 n_estimators는 400 설정. \n",
    "lgbm_wrapper = LGBMClassifier(\n",
    "    boosting_type= 'gbdt', \n",
    "    objective = 'binary', \n",
    "    device = 'gpu',\n",
    "    max_depth = params['max_depth'],\n",
    "    max_bin = params['max_bin'], \n",
    "    metric = params['metric'],\n",
    "    application = 'binary',\n",
    "    n_estimators = params['n_estimators'],\n",
    "   # random_state = 121,\n",
    "    num_leaves = params['num_leaves'], \n",
    "    #lambda_l1 = params['lambda_l1'], \n",
    "    #lambda_l2 = params['lambda_l2'], \n",
    "    #min_gain_to_split = params['min_gain_to_split'], \n",
    "    #bagging_fraction = params['bagging_fraction'], \n",
    "    #bagging_freq = params['bagging_freq'], \n",
    "    #feature_fraction = params['feature_fraction'],\n",
    "    learning_rate = params['learning_rate']\n",
    "    #num_iterations = params['num_iterations']\n",
    "    )\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능. \n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_wrapper.fit(X_train , y_train, early_stopping_rounds=100, eval_metric=\"logloss\", \\\n",
    "                 eval_set=evals, verbose=True)\n",
    "print(\"수행 시간: {0:.1f} 초 \".format(time.time() - start_time))\n",
    "preds = lgbm_wrapper.predict(X_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, preds, pred_proba)\n",
    "\n",
    "cm = confusion_matrix(y_test, preds)\n",
    "print(cm)\n",
    "# true/false positives/negatives\n",
    "(tp, fp, \n",
    " fn, tn) = cm.flatten()\n",
    "\n",
    "오탐률 = fp / (fp+tn)\n",
    "미탐률 = fn / (tp+fn) \n",
    "\n",
    "print(오탐률, 미탐률)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fe492d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 라이브러리 import\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e63998c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 0.9993, 정밀도: 0.9505, 재현율: 0.6194,    F1: 0.7500, AUC:0.9217\n",
      "[[85246    42]\n",
      " [   35   120]]\n",
      "0.25925925925925924 0.00041040794549782484\n",
      "DecisionTreeClassifier 정확도: 0.9991, 정밀도: 0.7407, 재현율: 0.7742,    F1: 0.7571, AUC:0.8869\n",
      "[[25249 60039]\n",
      " [   75    80]]\n",
      "0.9986693058766779 0.002961617438003475\n",
      "SVC 정확도: 0.2964, 정밀도: 0.0013, 재현율: 0.5161,    F1: 0.0027, AUC:0.3731\n",
      "[[84734   554]\n",
      " [   54   101]]\n",
      "0.8458015267175573 0.0006368825777232627\n",
      "GaussianNB 정확도: 0.9929, 정밀도: 0.1542, 재현율: 0.6516,    F1: 0.2494, AUC:0.9611\n",
      "수행 시간: 53.4 초 \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 개별 모델은 로지스틱 회귀와 KNN 임. \n",
    "lr_clf = LogisticRegression()\n",
    "#knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "C = 1                         # SVM의 regularization parameter\n",
    "svm_clf = svm.SVC(C=C, max_iter = 100, probability=True)\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기 \n",
    "vo_clf = VotingClassifier( estimators=[('dt_clf',dt_clf),('svm_clf',svm_clf),('nb_clf',nb_clf)] , voting='soft' )\n",
    "\n",
    "# VotingClassifier 학습/예측/평가. \n",
    "vo_clf.fit(X_train , y_train)\n",
    "pred = vo_clf.predict(X_test)\n",
    "pred_proba = vo_clf.predict_proba(X_test)[:, 1]\n",
    "confusion = confusion_matrix( y_test, pred)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "precision = precision_score(y_test , pred)\n",
    "recall = recall_score(y_test , pred)\n",
    "f1 = f1_score(y_test,pred)\n",
    "roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "\n",
    "print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# 개별 모델의 학습/예측/평가.\n",
    "classifiers = [dt_clf, svm_clf, nb_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_train , y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    pred_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print(cm)\n",
    "    # true/false positives/negatives\n",
    "    (tp, fp, \n",
    "     fn, tn) = cm.flatten()\n",
    "\n",
    "    오탐률 = fp / (fp+tn)\n",
    "    미탐률 = fn / (tp+fn) \n",
    "\n",
    "    print(오탐률, 미탐률)\n",
    "    \n",
    "    class_name= classifier.__class__.__name__\n",
    "    print('{0} 정확도: {1:.4f}, 정밀도: {2:.4f}, 재현율: {3:.4f},\\\n",
    "    F1: {4:.4f}, AUC:{5:.4f}'.format(class_name, accuracy, precision, recall, f1, roc_auc))\n",
    "    \n",
    "print(\"수행 시간: {0:.1f} 초 \".format(time.time() - start_time))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa431df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
