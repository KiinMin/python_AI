{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-19T07:41:33.176100Z",
     "start_time": "2021-08-19T07:41:23.653445Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "## 라이브러리 불러오기\n",
    "'''메인 라이브러리'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "import pickle, gzip\n",
    "\n",
    "'''시각화 관련 라이브러리'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "'''데이터 준비 및 모델 평가 관련 라이브러리'''\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "'''알고리즘 관련 라이브러리'''\n",
    "import lightgbm as lgb\n",
    "\n",
    "'''텐서플로 및 케라스 관련 라이브러리'''\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers import BatchNormalization, Input, Lambda\n",
    "from keras import regularizers\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('C://Users/USER/20210906/credit_card/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "\n",
    "# 수정된 get_clf_eval() 함수 \n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train[\"AMT\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test[\"AMT\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test,y_train, y_test= train_test_split(X, y,train_size=0.7, \n",
    "                                                    test_size=0.3, random_state=121)\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=0)\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "# start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=0)\n",
      "Wall time: 1min 43s\n",
      "오차 행렬\n",
      "[[85282     6]\n",
      " [   34   121]]\n",
      "정확도: 0.9995, 정밀도: 0.9528, 재현율: 0.7806,    F1: 0.8582, AUC:0.9436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train , y_train)\n",
    "%time print(rf_clf.fit(X_train , y_train))\n",
    "\n",
    "pred = rf_clf.predict(X_test)\n",
    "pred_proba = rf_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, MaxAbsScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "Wall time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# minmax scaler 선언 및 학습\n",
    "minmaxScaler = MinMaxScaler().fit(X_train)\n",
    "%time print(MinMaxScaler().fit(X_train))\n",
    "# train셋 내 feature들에 대하여 minmax scaling 수행\n",
    "X_train_minmax = minmaxScaler.transform(X_train) \n",
    "\n",
    "# test셋 내 feature들에 대하여 minmax scaling 수행\n",
    "X_test_minmax = minmaxScaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85282     6]\n",
      " [   34   121]]\n",
      "정확도: 0.9995, 정밀도: 0.9528, 재현율: 0.7806,    F1: 0.8582, AUC:0.9436\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train_minmax , y_train)\n",
    "pred = rf_clf.predict(X_test_minmax)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "pred_proba = rf_clf.predict_proba(X_test_minmax)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxAbsScaler()\n",
      "Wall time: 25.9 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# MaxAbsScaler 선언 및 학습\n",
    "maxabsScaler = MaxAbsScaler().fit(X_train)\n",
    "%time print(MaxAbsScaler().fit(X_train))\n",
    "# train셋 내 feature들에 대하여 maxabs scaling 수행\n",
    "X_train_maxabs = maxabsScaler.transform(X_train)\n",
    "\n",
    "# test셋 내 feature들에 대하여 maxabs scaling 수행\n",
    "X_test_maxabs = maxabsScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85282     6]\n",
      " [   34   121]]\n",
      "정확도: 0.9995, 정밀도: 0.9528, 재현율: 0.7806,    F1: 0.8582, AUC:0.9436\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train_maxabs , y_train)\n",
    "pred = rf_clf.predict(X_test_maxabs)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "pred_proba = rf_clf.predict_proba(X_test_maxabs)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "Wall time: 85.8 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standard scaler 선언 및 학습\n",
    "standardScaler = StandardScaler().fit(X_train)\n",
    "%time print(StandardScaler().fit(X_train))\n",
    "# train셋 내 feature들에 대하여 standard scaling 수행\n",
    "X_train_standard = standardScaler.transform(X_train)\n",
    "\n",
    "# test셋 내 feature들에 대하여 standard scaling 수행\n",
    "X_test_standard = standardScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85282     6]\n",
      " [   34   121]]\n",
      "정확도: 0.9995, 정밀도: 0.9528, 재현율: 0.7806,    F1: 0.8582, AUC:0.9436\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train_standard , y_train)\n",
    "pred = rf_clf.predict(X_test_standard)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "pred_proba = rf_clf.predict_proba(X_test_standard)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler()\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# RobustScaler 선언 및 학습\n",
    "robustScaler = RobustScaler().fit(X_train)\n",
    "%time print(RobustScaler().fit(X_train))\n",
    "# train셋 내 feature들에 대하여 robust scaling 수행\n",
    "X_train_robust = robustScaler.transform(X_train)\n",
    "\n",
    "# test셋 내 feature들에 대하여 robust scaling 수행\n",
    "X_test_robust = robustScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85282     6]\n",
      " [   34   121]]\n",
      "정확도: 0.9995, 정밀도: 0.9528, 재현율: 0.7806,    F1: 0.8582, AUC:0.9436\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train_robust , y_train)\n",
    "pred = rf_clf.predict(X_test_robust)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "pred_proba = rf_clf.predict_proba(X_test_robust)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizer()\n",
      "Wall time: 8.98 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = Normalizer()\n",
    "%time print(scaler.fit(X_train))\n",
    "# MaxAbsScaler 선언 및 학습\n",
    "X_train_normalScaler = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_normalScaler = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[85283     5]\n",
      " [   41   114]]\n",
      "정확도: 0.9995, 정밀도: 0.9580, 재현율: 0.7355,    F1: 0.8321, AUC:0.9458\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트 학습 및 별도의 테스트 셋으로 예측 성능 평가\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train_normalScaler , y_train)\n",
    "pred = rf_clf.predict(X_test_normalScaler)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "pred_proba = rf_clf.predict_proba(X_test_normalScaler)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test , pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
